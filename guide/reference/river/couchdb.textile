---
layout: guide
title: CouchDB River
cat: guide
sidebar: reference_river
---

p. The CouchDB River allows to automatically index couchdb and make it searchable using the excellent "_changes":http://guide.couchdb.org/draft/notifications.html stream couchdb provides. Setting it up is as simple as executing the following against elasticsearch:

<pre class="prettyprint">
curl -XPUT 'localhost:9200/_river/my_db/_meta' -d '{
    "type" : "couchdb",
    "couchdb" : {
        "host" : "localhost",
        "port" : 5984,
        "db" : "my_db",
        "filter" : null
    },
    "index" : {
        "index" : "my_db",
        "type" : "my_db",
        "bulk_size" : "100",
        "bulk_timeout" : "10ms"
    }
}'
</pre>

p. This call will create a river that uses the @_changes@ stream to index all data within couchdb. Moreover, any "future" changes will automatically be indexed as well, making your search index and couchdb synchronized at all times.

p. The couchdb river is provided as a plugin and can be installed using @plugin -install river-couchdb@.

p. On top of that, in case of a failover, the couchdb river will automatically be started on another elasticsearch node, and continue indexing from the last indexed seq.

h1. Bulking

p. Bulking is automatically done in order to speed up the indexing process. If within the specified @bulk_timeout@ more changes are detected, changes will be bulked up to @bulk_size@ before they are indexed.

h1. Filtering

p. The `changes` stream allows to provide a filter with parameters that will be used by couchdb to filter the stream of changes. Here is how ti can be configured:

<pre class="prettyprint lang-js">
{
    "couchdb" : {
        "filter" : "test",
        "filter_params" : {
            "param1" : "value1",
            "param2" : "value2"
        }
    }
}
</pre>

h1. Script Filters

p. Filtering can also be performed by providing a script (default to JavaScript) that will further process each changed item within the changes stream. The json provided to the script is under a var called @ctx@ with the relevant seq stream change (for example, @ctx.doc@ will refer to the document, or @ctx.deleted@ is the flag if its deleted or not).

p. Note, this feature requires the `lang-javascript` plugin.

p. The @ctx.doc@ can be changed and its value can will be indexed (assuming its not a deleted change). Also, if @ctx.ignore@ is set to true, the change seq will be ignore and not applied.

p. Other possible values that can be set are @ctx.index@ to control the index name to index the doc into, @ctx.type@ to control the (mapping) type to index into, @ctx._parent@ and @ctx._routing@.

p. Here is an example setting that adds `field1` with value `value1` to all docs:

<pre class="prettyprint lang-js">
{
    "type" : "couchdb",
    "couchdb" : {
        "script" : "ctx.doc.field1 = 'value1'"
    }
}
</pre>

h1. Basic Authentication

Basic Authentication can be used by passing the @user@ and @password@ attributes.

<pre class="prettyprint lang-js">
{
    "type" : "couchdb",
    "couchdb" : {
        "user" : "alice",
        "password" : "secret"
    }
}
</pre>

h1. HTTPS

To use HTTPS, pass the @protocol@ field. Most likely, you will also have to change the @port@. If you have unfixable problems with the servers certificates for any reason, you can disable hostname verification by passing @no_verify@.

<pre class="prettyprint lang-js">
{
    "type" : "couchdb",
    "couchdb" : {
        "protocol" : "https",
        "port" : 443,
        "no_verify" : "true"
    }
}
</pre>

h1. CouchDB views (since 0.19.x)

h2. User guide

You can fetch content from CouchDB views instead of getting documents.

As views return a collection of results (aka rows), ElasticSearch will index each row with an id like DOCID_seq where seq is the sequence number of each row.
If you get back 3 rows for one single change for document with ID=1234, the river will index 3 documents :

* 1234_1
* 1234_2
* 1234_3

Here is a way to define your river :

<pre class="prettyprint">
curl -XPUT 'localhost:9200/_river/my_db/_meta' -d '{
  "type":"couchdb",
  "couchdb": {
    "host":"localhost",
    "port":"5984",
    "db":"my_db",
    "view":"myviews/_view/myview",
    "viewIgnoreRemove":false
  }
}'
</pre>

Parameters are :
* @view@ : if not null, couchDB river will not fetch content from _changes API but only IDs and then will use the view to retrieve rows using the ID as a key. By default : null
* @viewIgnoreRemove@ : ask the river to ignore removal of rows if there is less rows after a document update. By default : false so non existing rows will be removed from elastic search.

For example, with the 3 rows described earlier, if you push a new version of the document 1234 in couchDB with only 2 docs :

* If @viewIgnoreRemove@ is @false@ (default), then
** 1234_1 will be updated
** 1234_2 will be updated
** 1234_3 will be removed

* If @viewIgnoreRemove@ is @true@, then
** 1234_1 will be updated
** 1234_2 will be updated
** 1234_3 will not be updated

h2. Curl recreation

We will consider that CouchDB is running and listening on localhost:5984 and Elasticsearch running on localhost:9200.

First, we create a mydb NoSQL DB on CouchDB :

<pre class="prettyprint">
$ curl -XDELETE http://localhost:5984/mydb

$ curl -XPUT http://localhost:5984/mydb
</pre>

First, we push 2 new documents (IDs 1 and 2) :

<pre class="prettyprint">
$ curl -XPUT http://localhost:5984/mydb/1 -d '{
   "myarray": [ 
     { "myfieldnum": 1, "myfieldstring": "one" }, 
     { "myfieldnum": 2, "myfieldstring": "two" },
     { "myfieldnum": 3, "myfieldstring": "three" }
  ]
}'

$ curl -XPUT http://localhost:5984/mydb/2 -d '{
   "myarray": [
           "myfieldnum": 4,
           "myfieldstring": "four"
       }
   ]
}'
</pre>

We define our view :

<pre class="prettyprint">
$ curl -XPOST http://localhost:5984/mydb/_design/myview -d '{
  "_id" : "_design/myviews",
  "views" : {
    "myview" : {
      "map": "function(doc) { list=doc.myarray; for(var i=0; i<list.length;i++) { var elt = { \"docid\" : doc._id, \"num\" : list[i].myfieldnum, \"text\" : list[i].myfieldstring }; elt = JSON.stringify( elt ); emit(doc._id, eval(\"(\"+elt+\")\") ); }; }"
   }
  }
}'
</pre>

It's time to create our river in ElasticSearch :

<pre class="prettyprint">
$ curl -XDELETE 'localhost:9200/my_db'

$ curl -XPUT 'localhost:9200/my_db'

$ curl -XPUT 'localhost:9200/_river/my_db/_meta' -d '{
  "type":"couchdb",
  "couchdb": {
    "host":"localhost",
    "port":"5984",
    "db":"my_db",
    "view":"myviews/_view/myview",
    "viewIgnoreRemove":false
  }
}'
</pre>

You should have now 4 documents in your ElasticSearch index : 1_1, 1_2, 1_3 and 2_1.

If you modify the document 1 by sending :

<pre class="prettyprint lang-js">
{
   "myarray": [
       {
           "myfieldnum": 1,
           "myfieldstring": "one"
       }, {
           "myfieldnum": 3,
           "myfieldstring": "three"
       }
   ]
}
</pre>

You should have 3 documents in your ElasticSearch index : 1_1, 1_2 and 2_1.
